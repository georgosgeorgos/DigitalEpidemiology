{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def routine_grid(model, parameters, X_train,y_train,X_test,y_test):\n",
    "    grid = GridSearchCV(model, parameters, scoring=\"r2\", cv=3)\n",
    "    grid.fit(X_train,y_train)\n",
    "    \n",
    "    model = grid.best_estimator_\n",
    "    model.fit(X_train, y_train)  \n",
    "    train_score = model.score(X_train,y_train)\n",
    "    test_score = model.score(X_test,y_test)\n",
    "    \n",
    "    return model, train_score, test_score\n",
    "\n",
    "def scorer(model, X, y):\n",
    "    e = 1 - np.sum( (model.predict(X) - y)**2) / np.sum((y.mean() - y)**2 )\n",
    "    return e\n",
    "\n",
    "def try_model(X,y,alphas,ls, iters = 15):\n",
    "    models = []\n",
    "    train_scores = []\n",
    "    test_scores =[]\n",
    "    for i in range(iters): \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_c, test_size=0.2, random_state=np.random.randint(1000))\n",
    "        model = ElasticNet(random_state=0, fit_intercept = True, normalize = True, max_iter= 10000)\n",
    "        par = {\"alpha\": alphas,\n",
    "                     \"l1_ratio\": ls }\n",
    "        model_best, best_score, test_score = routine_grid(model,par,X_train,y_train,X_test,y_test)\n",
    "        models.append(model_best)\n",
    "        train_scores.append(best_score)\n",
    "        test_scores.append(test_score)\n",
    "        print(test_score)\n",
    "    return(models, train_scores, test_scores)\n",
    "def show_coefs(model,X):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    coef = pd.Series(model.coef_, index = X.columns).sort_values()\n",
    "    imp_coef = pd.concat([coef.head(10), coef.tail(10)])\n",
    "    imp_coef.plot(kind = \"barh\")\n",
    "    plt.title(\"Coefficients in the Model\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306, 163)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_df=pd.read_csv(\"../data/matrix/matrix_df_163.csv\", index_col=0)\n",
    "matrix_df = matrix_df.fillna(matrix_df.mean())\n",
    "results = dict()\n",
    "matrix_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data:** In the following matrix we have:\n",
    "* 101 features extracted from Google trends\n",
    "* year and state_id feature that let us to take advantage from time and location of the state\n",
    "* latitude and longitude that we are able to use to specify geografical position more explicitly\n",
    "* income and employment from US Census Bureau\n",
    "* percentage of people without health insurance\n",
    "* two target values: crude prevalence, age-adjusted prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addiction</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>america</th>\n",
       "      <th>animal</th>\n",
       "      <th>antidepressants</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>app</th>\n",
       "      <th>ashwagandha</th>\n",
       "      <th>association</th>\n",
       "      <th>attack</th>\n",
       "      <th>...</th>\n",
       "      <th>years</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>prevalence_a</th>\n",
       "      <th>prevalence_c</th>\n",
       "      <th>income</th>\n",
       "      <th>insurance</th>\n",
       "      <th>unemployment</th>\n",
       "      <th>states</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>45</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>76</td>\n",
       "      <td>84</td>\n",
       "      <td>48</td>\n",
       "      <td>65</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>79</td>\n",
       "      <td>21.1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>42590</td>\n",
       "      <td>10.135784</td>\n",
       "      <td>5.926667</td>\n",
       "      <td>0</td>\n",
       "      <td>32.806671</td>\n",
       "      <td>-86.791130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>74</td>\n",
       "      <td>93</td>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "      <td>75</td>\n",
       "      <td>69</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>53</td>\n",
       "      <td>16.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>57431</td>\n",
       "      <td>10.135784</td>\n",
       "      <td>5.926667</td>\n",
       "      <td>1</td>\n",
       "      <td>61.370716</td>\n",
       "      <td>-152.404419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>84</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>78</td>\n",
       "      <td>81</td>\n",
       "      <td>98</td>\n",
       "      <td>51</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>64</td>\n",
       "      <td>17.3</td>\n",
       "      <td>17.5</td>\n",
       "      <td>48621</td>\n",
       "      <td>10.135784</td>\n",
       "      <td>5.926667</td>\n",
       "      <td>2</td>\n",
       "      <td>33.729759</td>\n",
       "      <td>-111.431221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>62</td>\n",
       "      <td>73</td>\n",
       "      <td>82</td>\n",
       "      <td>79</td>\n",
       "      <td>83</td>\n",
       "      <td>51</td>\n",
       "      <td>74</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>77</td>\n",
       "      <td>22.9</td>\n",
       "      <td>22.8</td>\n",
       "      <td>41302</td>\n",
       "      <td>10.135784</td>\n",
       "      <td>5.926667</td>\n",
       "      <td>3</td>\n",
       "      <td>34.969704</td>\n",
       "      <td>-92.373123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "      <td>64</td>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "      <td>91</td>\n",
       "      <td>62</td>\n",
       "      <td>40</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>49</td>\n",
       "      <td>12.1</td>\n",
       "      <td>12.3</td>\n",
       "      <td>53367</td>\n",
       "      <td>10.135784</td>\n",
       "      <td>5.926667</td>\n",
       "      <td>4</td>\n",
       "      <td>36.116203</td>\n",
       "      <td>-119.681564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            addiction  alcohol  america  animal  antidepressants  anxiety  \\\n",
       "Alabama            72       76       45      73               85       76   \n",
       "Alaska             74       93       65      83               68       71   \n",
       "Arizona            76       77       84      71               71       78   \n",
       "Arkansas           73       73       62      73               82       79   \n",
       "California         64       77       88      64               56       68   \n",
       "\n",
       "            app  ashwagandha  association  attack     ...      years  zoloft  \\\n",
       "Alabama      84           48           65      87     ...         91      79   \n",
       "Alaska       75           69           94      95     ...         82      53   \n",
       "Arizona      81           98           51      85     ...         86      64   \n",
       "Arkansas     83           51           74      84     ...         89      77   \n",
       "California   91           62           40      78     ...         84      49   \n",
       "\n",
       "            prevalence_a  prevalence_c  income  insurance  unemployment  \\\n",
       "Alabama             21.1          21.2   42590  10.135784      5.926667   \n",
       "Alaska              16.5          16.5   57431  10.135784      5.926667   \n",
       "Arizona             17.3          17.5   48621  10.135784      5.926667   \n",
       "Arkansas            22.9          22.8   41302  10.135784      5.926667   \n",
       "California          12.1          12.3   53367  10.135784      5.926667   \n",
       "\n",
       "            states   latitude   longitude  \n",
       "Alabama          0  32.806671  -86.791130  \n",
       "Alaska           1  61.370716 -152.404419  \n",
       "Arizona          2  33.729759 -111.431221  \n",
       "Arkansas         3  34.969704  -92.373123  \n",
       "California       4  36.116203 -119.681564  \n",
       "\n",
       "[5 rows x 163 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elastic net:** Giving the way we selected features the obtained matrix has a lot of redundant information. Hence, in order to prevent overfitting we were forced to choose a model with some regulization components. The most popular of them are Ridge and Lasso regression or elastic net technique which is a linear regression with combined L1 and L2 priors as regularizers.\n",
    "With Elastic net we could also use Elastic net  mixing parameter, with $0 <= l1ratio <= 1$. For $l1ratio = 0$ the penalty is an $L2$ penalty. For $l1ratio = 1$ it is an $L1$ penalty. For $0 < l1ratio < 1$, the penalty is a combination of $L1$ and $L2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation:** In order to make sure that our result isn't biased in any way we made function *try_model()* which performs following steps:\n",
    "1. it separates 20 % of the data as a test set\n",
    "2. does greed search of the best alpha (penalty term) and l1 (mixing parameter) and veryfies it with 3 folds cross validation\n",
    "3. reports the $R^2$ of the test set\n",
    "4. repeats steps 1-3 several time in order to give information about variability of the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Google Trends-based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for age-adjusted prevalence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_a = matrix_df[\"prevalence_a\"]\n",
    "y_c = matrix_df[\"prevalence_c\"]\n",
    "X = matrix_df.drop([\"prevalence_a\",\"prevalence_c\",\"income\",\"insurance\", \"unemployment\"], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.836037569375\n",
      "0.755155446244\n",
      "0.79130830183\n",
      "0.69454177691\n",
      "0.835676916643\n",
      "0.705307568823\n",
      "0.749888649801\n",
      "0.776780779777\n",
      "0.802744416767\n",
      "0.795611467021\n",
      "0.765907549519\n",
      "0.771875281316\n",
      "0.788800575936\n",
      "0.753166125565\n",
      "0.741946931059\n"
     ]
    }
   ],
   "source": [
    "alphas = np.array([0.0008,  0.0009,  0.001 ,  0.0011]) #were pre-selected with a bigger search procedure\n",
    "ls = np.arange(0.1, 0.9, 0.1)\n",
    "\n",
    "models_a, train_scores_a, test_scores_a = try_model(X,y_a,alphas,ls, iters = 15)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean $R^2$ coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77098329043901404"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"trends only for age-adj. prev.\"] = np.mean(test_scores_a)\n",
    "np.mean(test_scores_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models_a[0] # since all the models are the same\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what features were selected as the most relevant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_coefs(models_a[0],X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result seem meaningful: as features that correlates possitively with depression we can extract really staight connections. Gor instance there are a lot of medcine related terms: doctor, bill, prozac (antidepressant), trazodone (antidepressant) and so on.\n",
    "\n",
    "Also, we found interesting that term \"orem\" appeared to be meaningful. Orem is a city in Utah and Utah is one of the states with very high level of depression according to ground truth data.\n",
    "\n",
    "Term \"robin\" seem meningless in some sence, but in fact it refers to a tragic story of comedian Robin Williams who commited suicide because of his depression in August 2014.\n",
    "\n",
    "In the down part of the plot we are able to see many positive terms such as benefits, vitomin, friends, code, party. Probably, we can conclude from this that people who concerned about these terms don't seem to be interested in depression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for crude prevalence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "models_c, train_scores_c, test_scores_c = try_model(X,y_c,alphas,ls, iters = 15)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results[\"trends only for crude prev.\"] = np.mean(test_scores_c)\n",
    "np.mean(test_scores_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models_c[0] # since all the models are the same\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, elastic search picked the same values for predicting crude prevalence and this makes sense since as we discovered before, the correlation between these two target features are almost 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_coefs(models_c[0],X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the feature selection is more or less the same as for age-adjusted prevalence targer value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Google Trends + census features (income and employment) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for age-adjusted prevalence prediction with census features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = matrix_df.drop([\"prevalence_a\",\"prevalence_c\",\"insurance\"], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models_a, train_scores_a, test_scores_a = try_model(X,y_a,alphas,ls, iters = 15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results[\"trends + census data for age-adj. prev.\"] = np.mean(test_scores_a)\n",
    "np.mean(test_scores_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models_a[0] # since all the models are the same\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_coefs(model,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, unemployment rate correlates a lot with ground truth data and hense significally increasing quality of the prediction.\n",
    "\n",
    "On the other hand, income data doesn't seem to have any effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for crude prevalence prediction with census features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "models_c, train_scores_c, test_scores_c = try_model(X,y_c,alphas,ls, iters = 15)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results[\"trends + census data for crude prev.\"] = np.mean(test_scores_c)\n",
    "np.mean(test_scores_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models_c[0]\n",
    "show_coefs(model,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see more or less the same result as we obtained for age-adjasted prevalence with respect to $r^2$ and selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Google Trends + census features (income and employment) + insurance data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for age-adjusted prevalence prediction with census features + insurance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = matrix_df.drop([\"prevalence_a\",\"prevalence_c\"], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "models_a, train_scores_a, test_scores_a = try_model(X,y_a,alphas,ls, iters = 15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results[\"trends + census data + insurance data for age-adj. prev.\"] = np.mean(test_scores_a)\n",
    "np.mean(test_scores_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models_a[0] # since all the models are the same\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_coefs(model,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although $R^2$ didn't seem to improve, we are able to see that insurance data appear to be a significant feature as well "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for crude prevalence prediction with census features + insurance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "models_c, train_scores_c, test_scores_c = try_model(X,y_c,alphas,ls, iters = 15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results[\"trends + census data + insurance data for crude prev.\"] = np.mean(test_scores_c)\n",
    "np.mean(test_scores_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models_c[0] # since all the models are the same\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_coefs(model,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res  = pd.DataFrame.from_dict(results,orient = \"index\")\n",
    "res.columns = [\"r2\"]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
