{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_cv(X_train, y_train, alphas, cv_type, k=5):\n",
    "    R_cv=[]\n",
    "    R_t=[]\n",
    "    for a in alphas:\n",
    "        \n",
    "        model=lm.Lasso(alpha=a, max_iter=1000000)\n",
    "        if cv_type==\"k\":\n",
    "            r_cv, r_t = k_fold_cv(model, X_train, y_train, k)\n",
    "        else:\n",
    "            r_cv, r_t = leave_one_out(model, X_train, y_train)\n",
    "            \n",
    "        R_cv.append(r_cv)\n",
    "        R_t.append(r_t)\n",
    "    return R_cv, R_t\n",
    "\n",
    "def leave_one_out(model, X_train, y_train):\n",
    "    R_train=[]\n",
    "    R_cv=[]\n",
    "    y=y_train.values\n",
    "    for i in range(len(y)):\n",
    "        X_sample_train=np.delete( X_train, [i], 0 )\n",
    "        y_sample_train=np.delete( y, [i], 0 )\n",
    "        X_sample_cv=X_train[i]\n",
    "        X_sample_cv=np.reshape(X_sample_cv, (1,-1))\n",
    "        y_sample_cv=y[i]\n",
    "        y_sample_cv=np.reshape(y_sample_cv, (1,-1))\n",
    "        \n",
    "        model.fit(X_sample_train, y_sample_train)\n",
    "        r_t=scorer(model, X_sample_train, y_sample_train)\n",
    "        r = model.predict(X_sample_cv)[0]\n",
    "        R_train.append(r_t)\n",
    "        R_cv.append(r)\n",
    "        \n",
    "    R_cv = 1 - np.sum(( R_cv - y )**2) / np.sum((y.mean() - y)**2)\n",
    "    return np.mean(R_cv), np.mean(R_train)\n",
    "\n",
    "def k_fold_cv(model, X_train, y_train, k):\n",
    "    n = len(y_train) // k  \n",
    "    R_train=[]\n",
    "    R_cv=[]\n",
    "    #tot=0\n",
    "    for i in range(0, k-1):\n",
    "        X_sample = X_train.copy()\n",
    "        y_sample = y_train.values\n",
    "        X_sample_train=np.delete( X_sample, [j for j in range((i*n),((i+1)*n))], 0 )\n",
    "        y_sample_train=np.delete( y_sample, [j for j in range((i*n),((i+1)*n))], 0 )\n",
    "        \n",
    "        X_sample_cv=X_sample[(i*n):((i+1)*n)]\n",
    "        y_sample_cv=y_sample[(i*n):((i+1)*n)]\n",
    "        \n",
    "        model.fit(X_sample_train, y_sample_train)\n",
    "        r_t=scorer(model, X_sample_train, y_sample_train)\n",
    "        r=scorer(model, X_sample_cv, y_sample_cv)\n",
    "        R_train.append(r_t)\n",
    "        R_cv.append(r)\n",
    "        #tot = tot + len(y_sample)\n",
    "    X_sample = X_train.copy()\n",
    "    y_sample = y_train.copy()\n",
    "\n",
    "    X_sample_train=X_sample[:((k-1)*n)]\n",
    "    y_sample_train=y_sample[:((k-1)*n)]\n",
    "    X_sample_cv=X_sample[((k-1)*n):]\n",
    "    y_sample_cv=y_sample[((k-1)*n):]\n",
    "    \n",
    "    model.fit(X_sample_train, y_sample_train)\n",
    "    r_t=scorer(model, X_sample_train, y_sample_train)\n",
    "    r=scorer(model, X_sample_cv, y_sample_cv)\n",
    "    R_train.append(r_t)\n",
    "    R_cv.append(r)\n",
    "    #tot = tot + len(y_sample)\n",
    "    #print(tot)\n",
    "    return np.mean(R_cv), np.mean(R_train)\n",
    "\n",
    "def k_fold_test(model, X_test, y_test, k=2):\n",
    "    n = len(y_test) // k    \n",
    "    R=[]\n",
    "    #tot=0\n",
    "    for i in range(0,k-1):\n",
    "        \n",
    "        X_sample=X_test[(i*n):((i+1)*n)]\n",
    "        y_sample=y_test[(i*n):((i+1)*n)]\n",
    "        r=scorer(model, X_sample, y_sample)\n",
    "        R.append(r)\n",
    "        #tot = tot + len(y_sample)\n",
    "    \n",
    "    X_sample=X_test[((k-1)*n):]\n",
    "    y_sample=y_test[((k-1)*n):]\n",
    "    r=scorer(model, X_sample, y_sample)\n",
    "    R.append(r)\n",
    "    #tot = tot + len(y_sample)\n",
    "    #print(tot)\n",
    "    return np.mean(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error(model, X, y):\n",
    "    e = np.sum((model.predict(X) - y)**2) / len(y)\n",
    "    return e\n",
    "\n",
    "def scorer(model, X, y):\n",
    "    e = 1 - np.sum( (model.predict(X) - y)**2) / np.sum((y.mean() - y)**2 )\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix_df=pd.read_csv(\"../data/matrix/matrix_df_159.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(matrix_df, l=[\"prevalence_c\", \"prevalence_a\"]):\n",
    "    X = matrix_df.drop(l , axis=1, inplace=False)\n",
    "    \n",
    "    y_c = matrix_df[\"prevalence_c\"]\n",
    "    y_a = matrix_df[\"prevalence_a\"]\n",
    "    \n",
    "    X = X.fillna(X.mean())\n",
    "    return X, y_a, y_c\n",
    "\n",
    "def split_scale(X, y, test_size, r, cv_type):\n",
    "    \n",
    "    scaler=RobustScaler()\n",
    "    if cv_type == \"k\":\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=r)\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_train=shuffle(X)\n",
    "        y_train=shuffle(y)\n",
    "        X_test=[]\n",
    "        y_test=[]\n",
    "        \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_lasso(X_train, X_test, y_train, y_test, cv_type, k):\n",
    "    \n",
    "    alphas= [0.00001, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 1.0]\n",
    "    R_cv, R_t = model_cv(X_train, y_train, alphas, cv_type=cv_type, k=k)\n",
    "    alpha=alphas[np.argmax(R_cv)]\n",
    "    \n",
    "    model=lm.Lasso(alpha=alpha, max_iter=1000000)\n",
    "    if cv_type==\"k\":\n",
    "        model.fit(X_train, y_train)\n",
    "        R_test=k_fold_test(model, X_test, y_test)\n",
    "        return model, R_t, R_cv, R_test\n",
    "    else:\n",
    "        return model, R_cv, R_t, _\n",
    "\n",
    "def main_lasso(matrix_df, l=[\"prevalence_c\", \"prevalence_a\", \"income\", \"insurance\"], test_size=0.3, flag=\"c\", n=20, cv_type=\"k\", k=5):\n",
    "    \n",
    "    X, y_a, y_c = preprocess(matrix_df, l)\n",
    "    R=[]\n",
    "    if flag==\"c\":\n",
    "        y=y_c\n",
    "    else:\n",
    "        y=y_a\n",
    "        \n",
    "    for _ in range(n):\n",
    "        X_train, X_test, y_train, y_test = split_scale(X, y, test_size=test_size, r=np.random.randint(100), cv_type=cv_type)\n",
    "        model, r_train, r_cv, r_test = run_lasso(X_train, X_test, y_train, y_test, cv_type, k)\n",
    "\n",
    "        R.append([model.alpha, r_test])\n",
    "    R=np.array(R)\n",
    "    best_alpha=np.mean(R[:,0])\n",
    "    r=np.mean(R[:,1])\n",
    "    return best_alpha, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def routine_grid(model, parameters, X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    routine for cross-validation with different hyper-parameters\n",
    "    '''\n",
    "    grid = GridSearchCV(model, parameters, scoring=\"r2\", cv=5)\n",
    "    grid.fit(X_train,y_train)\n",
    "    \n",
    "    model = grid.best_estimator_\n",
    "    model.fit(X_train, y_train)  \n",
    "    best_score = model.score(X_train,y_train)\n",
    "    test_score = k_fold_test(model, X_test, y_test)\n",
    "    \n",
    "    return model, best_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main_grid(matrix_df):\n",
    "    '''\n",
    "    regression model selection\n",
    "    '''\n",
    "    \n",
    "    lasso={\"alpha\": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0]}\n",
    "    ridge={\"alpha\": [0.01, 0.1, 1.0, 10.0, 50.0, 100.0]}\n",
    "    elasticNet={\"alpha\":[0.00001, 0.0001, 0.001,0.01, 0.1, 1.0], \"l1_ratio\":[0.1, 0.5, 0.7, 0.8, 0.9, 1.0]}\n",
    "    kernel_ridge={\"alpha\": [1e0, 0.1, 1e-2, 1e-3], \"gamma\": np.logspace(-2, 2, 5)}\n",
    "    models = {\"lasso\": lm.Lasso(max_iter=100000), \"elasticNet\": lm.ElasticNet(max_iter=100000), \n",
    "              \"ridge\": lm.Ridge(max_iter=100000), \"kernelRidge\": KernelRidge(kernel='rbf')}\n",
    "    parameters = {\"lasso\": lasso, \"elasticNet\": elasticNet, \"ridge\": ridge, \"kernelRidge\": kernel_ridge}\n",
    "    res = []\n",
    "    \n",
    "    X, y_a, y_c = preprocess(matrix_df)\n",
    "    X_train, X_test, y_train, y_test = split_scale(X, y_c, 0.1, r=np.random.randint(100), cv_type=\"k\")\n",
    "    \n",
    "    for m in [\"lasso\", \"elasticNet\", \"ridge\"]:\n",
    "\n",
    "        model = models[m]\n",
    "        par = parameters[m]\n",
    "        \n",
    "\n",
    "        model, best_score, test_score = routine_grid(model, par, X_train, y_train, X_test, y_test)\n",
    "        res.append([model,best_score,test_score])\n",
    "        print(m)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_df=pd.read_csv(\"../data/matrix/matrix_df_163.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso\n",
      "elasticNet\n",
      "ridge\n",
      "lasso\n",
      "elasticNet\n",
      "ridge\n",
      "lasso\n",
      "elasticNet\n",
      "ridge\n",
      "lasso\n",
      "elasticNet\n",
      "ridge\n",
      "lasso\n",
      "elasticNet\n",
      "ridge\n",
      "lasso\n",
      "elasticNet\n",
      "ridge\n",
      "lasso\n",
      "elasticNet\n",
      "ridge\n",
      "lasso\n",
      "elasticNet\n",
      "ridge\n",
      "lasso\n",
      "elasticNet\n",
      "ridge\n",
      "lasso\n",
      "elasticNet\n",
      "ridge\n"
     ]
    }
   ],
   "source": [
    "r_lasso=[]\n",
    "r_ridge=[]\n",
    "r_elastic=[]\n",
    "\n",
    "for i in range(10):\n",
    "    res=main_grid(matrix_df)\n",
    "    r_lasso.append(res[0][2])\n",
    "    r_elastic.append(res[1][2])\n",
    "    r_ridge.append(res[2][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77167360573471044"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(r_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76067111036787738"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(r_elastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77259076404230764"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(r_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#matrix_spatial_average=pd.DataFrame(index=matrix_spatial_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for c in cols:\n",
    "#     temp=matrix_spatial_df[c]\n",
    "#     temp=np.mean(temp, axis=1)\n",
    "#     temp=pd.DataFrame(temp, columns=[c], index=matrix_spatial_df.index)\n",
    "#     matrix_spatial_average=pd.concat([matrix_spatial_average, temp], axis=1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
